{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T07:53:15.387884Z","iopub.execute_input":"2025-04-05T07:53:15.388084Z","iopub.status.idle":"2025-04-05T07:53:16.064688Z","shell.execute_reply.started":"2025-04-05T07:53:15.388064Z","shell.execute_reply":"2025-04-05T07:53:16.063826Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install medmnist albumentations opencv-python matplotlib pillow\n","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-04-05T05:16:43.390505Z","iopub.execute_input":"2025-04-05T05:16:43.390839Z","iopub.status.idle":"2025-04-05T05:16:46.852390Z","shell.execute_reply.started":"2025-04-05T05:16:43.390814Z","shell.execute_reply":"2025-04-05T05:16:46.851218Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (3.0.2)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\nRequirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.7.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.11.0a2)\nRequirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\nRequirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.11.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.17.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->medmnist) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->medmnist) (2024.2.0)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install torch torchvision albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:37:14.925265Z","iopub.execute_input":"2025-04-05T04:37:14.925637Z","iopub.status.idle":"2025-04-05T04:37:18.290805Z","shell.execute_reply.started":"2025-04-05T04:37:14.925600Z","shell.execute_reply":"2025-04-05T04:37:18.289819Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.11.0a2)\nRequirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\nRequirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.11.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.29.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install scikit-learn tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:19:16.505176Z","iopub.execute_input":"2025-04-05T05:19:16.505513Z","iopub.status.idle":"2025-04-05T05:19:19.895001Z","shell.execute_reply.started":"2025-04-05T05:19:16.505484Z","shell.execute_reply":"2025-04-05T05:19:19.894102Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Save this as medmnist_preprocessing.py and run locally\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport albumentations as A\nfrom medmnist import OCTMNIST, BreastMNIST, PneumoniaMNIST, RetinaMNIST, INFO\n\n# Output directory\nos.makedirs('split_data', exist_ok=True)\n\n# Offsets for label uniqueness\noffsets = {\n    'octmnist': 0,\n    'breastmnist': len(INFO['octmnist']['label']),\n    'pneumoniamnist': len(INFO['octmnist']['label']) + len(INFO['breastmnist']['label']),\n    'retinamnist': len(INFO['octmnist']['label']) + len(INFO['breastmnist']['label']) + len(INFO['pneumoniamnist']['label']),\n}\n\n# Preprocessing\ndef preprocess_general(img):\n    if img.ndim == 3 and img.shape[-1] == 3:\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    elif img.ndim == 3 and img.shape[-1] == 1:\n        img = img.squeeze()\n    return img.astype(np.float32) / 255.0\n\ndef preprocess_retina(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    denoised = cv2.medianBlur(gray, 3)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    return clahe.apply(denoised).astype(np.float32) / 255.0\n\n# Load + preprocess\ndef load_and_preprocess(dataset_cls, offset, is_retina=False):\n    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n    for split_name in ['train', 'val', 'test']:\n        dataset = dataset_cls(split=split_name, download=True)\n        for img, label in zip(dataset.imgs, dataset.labels.squeeze()):\n            label += offset\n            proc_img = preprocess_retina(img) if is_retina else preprocess_general(img)\n            if split_name == 'train':\n                X_train.append(proc_img)\n                y_train.append(label)\n            elif split_name == 'val':\n                X_val.append(proc_img)\n                y_val.append(label)\n            else:\n                X_test.append(proc_img)\n                y_test.append(label)\n    return X_train, y_train, X_val, y_val, X_test, y_test\n\n# Master load\nX_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\nfor name, cls in zip(['octmnist', 'breastmnist', 'pneumoniamnist', 'retinamnist'],\n                     [OCTMNIST, BreastMNIST, PneumoniaMNIST, RetinaMNIST]):\n    is_retina = (name == 'retinamnist')\n    Xt, yt, Xv, yv, Xte, yte = load_and_preprocess(cls, offsets[name], is_retina)\n    X_train += Xt\n    y_train += yt\n    X_val += Xv\n    y_val += yv\n    X_test += Xte\n    y_test += yte\n\nX_train, y_train = np.array(X_train), np.array(y_train)\nX_val, y_val = np.array(X_val), np.array(y_val)\nX_test, y_test = np.array(X_test), np.array(y_test)\n\n# Print distributions\ndef print_distribution(name, labels):\n    print(f\"\\n📊 {name} Set Class Distribution:\")\n    for cls, count in zip(*np.unique(labels, return_counts=True)):\n        print(f\"Class {cls}: {count}\")\n\nprint_distribution(\"Train\", y_train)\nprint_distribution(\"Validation\", y_val)\nprint_distribution(\"Test\", y_test)\n\n# Augmentation\nAUGMENT_CLASSES = [cls for cls, count in zip(*np.unique(y_train, return_counts=True)) if count < 4000]\naugment = A.Compose([\n    A.Rotate(limit=15, p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),\n    A.RandomBrightnessContrast(p=0.3),\n    A.ElasticTransform(p=0.2),\n])\n\naug_imgs, aug_labels = [], []\nfor cls in AUGMENT_CLASSES:\n    cls_idxs = np.where(y_train == cls)[0]\n    cls_imgs = X_train[cls_idxs]\n    needed = 4000 - len(cls_imgs)\n    for _ in range(needed):\n        img = cls_imgs[np.random.randint(len(cls_imgs))]\n        img_aug = augment(image=(img * 255).astype(np.uint8))['image']\n        aug_imgs.append(img_aug.astype(np.float32) / 255.0)\n        aug_labels.append(cls)\n\n# Append\nif aug_imgs:\n    X_train = np.concatenate([X_train, np.stack(aug_imgs)])\n    y_train = np.concatenate([y_train, np.array(aug_labels)])\n    print(f\"\\n✅ Augmented with {len(aug_labels)} new samples\")\n\n# Save\ndef save_split(X, y, path):\n    df = pd.DataFrame(X.reshape((X.shape[0], -1)))\n    df['label'] = y\n    df.to_csv(path, index=False)\n\nsave_split(X_train, y_train, \"split_data/train.csv\")\nsave_split(X_val, y_val, \"split_data/val.csv\")\nsave_split(X_test, y_test, \"split_data/test.csv\")\n\nprint(\"\\n✅ Saved train, val, and test CSVs to 'split_data/'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:28:27.314693Z","iopub.execute_input":"2025-04-05T05:28:27.315048Z","iopub.status.idle":"2025-04-05T05:30:07.164088Z","shell.execute_reply.started":"2025-04-05T05:28:27.315023Z","shell.execute_reply":"2025-04-05T05:30:07.163100Z"}},"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/octmnist.npz\nUsing downloaded and verified file: /root/.medmnist/octmnist.npz\nUsing downloaded and verified file: /root/.medmnist/octmnist.npz\nUsing downloaded and verified file: /root/.medmnist/breastmnist.npz\nUsing downloaded and verified file: /root/.medmnist/breastmnist.npz\nUsing downloaded and verified file: /root/.medmnist/breastmnist.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\nUsing downloaded and verified file: /root/.medmnist/retinamnist.npz\nUsing downloaded and verified file: /root/.medmnist/retinamnist.npz\nUsing downloaded and verified file: /root/.medmnist/retinamnist.npz\n\n📊 Train Set Class Distribution:\nClass 0: 33484\nClass 1: 10213\nClass 2: 7754\nClass 3: 46026\nClass 4: 147\nClass 5: 399\nClass 6: 1214\nClass 7: 3494\nClass 8: 486\nClass 9: 128\nClass 10: 206\nClass 11: 194\nClass 12: 66\n\n📊 Validation Set Class Distribution:\nClass 0: 3721\nClass 1: 1135\nClass 2: 862\nClass 3: 5114\nClass 4: 21\nClass 5: 57\nClass 6: 135\nClass 7: 389\nClass 8: 54\nClass 9: 12\nClass 10: 28\nClass 11: 20\nClass 12: 6\n\n📊 Test Set Class Distribution:\nClass 0: 250\nClass 1: 250\nClass 2: 250\nClass 3: 250\nClass 4: 42\nClass 5: 114\nClass 6: 234\nClass 7: 390\nClass 8: 174\nClass 9: 46\nClass 10: 92\nClass 11: 68\nClass 12: 20\n\n✅ Augmented with 29666 new samples\n\n✅ Saved train, val, and test CSVs to 'split_data/'\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load processed splits\ndf_train = pd.read_csv(\"split_data/train.csv\")\ndf_val = pd.read_csv(\"split_data/val.csv\")\ndf_test = pd.read_csv(\"split_data/test.csv\")\n\ndef print_class_distribution(df, name):\n    labels = df['label'].values\n    unique, counts = np.unique(labels, return_counts=True)\n    print(f\"\\n📊 {name} Set Class Distribution:\")\n    for u, c in zip(unique, counts):\n        print(f\"Class {u}: {c}\")\n\nprint_class_distribution(df_train, \"Train\")\nprint_class_distribution(df_val, \"Validation\")\nprint_class_distribution(df_test, \"Test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:31:36.056013Z","iopub.execute_input":"2025-04-05T05:31:36.056385Z","iopub.status.idle":"2025-04-05T05:31:52.819244Z","shell.execute_reply.started":"2025-04-05T05:31:36.056343Z","shell.execute_reply":"2025-04-05T05:31:52.818502Z"}},"outputs":[{"name":"stdout","text":"\n📊 Train Set Class Distribution:\nClass 0: 33484\nClass 1: 10213\nClass 2: 7754\nClass 3: 46026\nClass 4: 4000\nClass 5: 4000\nClass 6: 4000\nClass 7: 4000\nClass 8: 4000\nClass 9: 4000\nClass 10: 4000\nClass 11: 4000\nClass 12: 4000\n\n📊 Validation Set Class Distribution:\nClass 0: 3721\nClass 1: 1135\nClass 2: 862\nClass 3: 5114\nClass 4: 21\nClass 5: 57\nClass 6: 135\nClass 7: 389\nClass 8: 54\nClass 9: 12\nClass 10: 28\nClass 11: 20\nClass 12: 6\n\n📊 Test Set Class Distribution:\nClass 0: 250\nClass 1: 250\nClass 2: 250\nClass 3: 250\nClass 4: 42\nClass 5: 114\nClass 6: 234\nClass 7: 390\nClass 8: 174\nClass 9: 46\nClass 10: 92\nClass 11: 68\nClass 12: 20\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n# Load pretrained ResNet-18\nresnet18 = models.resnet18(pretrained=True)\n\n# Modify final FC layer for 13 classes\nnum_ftrs = resnet18.fc.in_features\nresnet18.fc = nn.Linear(num_ftrs, 13)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:32:54.123398Z","iopub.execute_input":"2025-04-05T05:32:54.123767Z","iopub.status.idle":"2025-04-05T05:32:54.328450Z","shell.execute_reply.started":"2025-04-05T05:32:54.123732Z","shell.execute_reply":"2025-04-05T05:32:54.327792Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport torch\n\nclass MedDataset(Dataset):\n    def __init__(self, csv_path):\n        df = pd.read_csv(csv_path)\n        self.X = df.drop(columns=['label']).values.reshape(-1, 1, 28, 28).astype(np.float32)\n        self.y = df['label'].values.astype(np.int64)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n\n# Dataloaders\nbatch_size = 128\n\ntrain_loader = DataLoader(MedDataset('split_data/train.csv'), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(MedDataset('split_data/val.csv'), batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(MedDataset('split_data/test.csv'), batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:33:09.894025Z","iopub.execute_input":"2025-04-05T05:33:09.894323Z","iopub.status.idle":"2025-04-05T05:33:27.117795Z","shell.execute_reply.started":"2025-04-05T05:33:09.894303Z","shell.execute_reply":"2025-04-05T05:33:27.117079Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet18 = resnet18.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=1e-4)\n\ndef evaluate(model, loader):\n    model.eval()\n    y_true, y_pred, y_probs = [], [], []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            X = X.repeat(1, 3, 1, 1)  # Convert 1 channel to 3 channels for ResNet\n\n            outputs = model(X)\n            probs = torch.softmax(outputs, dim=1)\n            preds = torch.argmax(probs, dim=1)\n\n            y_true.extend(y.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            y_probs.extend(probs.cpu().numpy())\n\n    # AUC for multi-class\n    try:\n        auc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n    except:\n        auc = 0.0\n\n    return {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'f1': f1_score(y_true, y_pred, average='weighted'),\n        'precision': precision_score(y_true, y_pred, average='weighted'),\n        'recall': recall_score(y_true, y_pred, average='macro'),\n        'auc': auc\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 10  # You can tweak this based on val loss\nbest_val_acc = 0.0\n\nfor epoch in range(epochs):\n    resnet18.train()\n    train_losses = []\n\n    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n        X, y = X.to(device), y.to(device)\n        X = X.repeat(1, 3, 1, 1)  # 1-channel → 3-channel\n\n        optimizer.zero_grad()\n        outputs = resnet18(X)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.item())\n\n    train_metrics = evaluate(resnet18, train_loader)\n    val_metrics = evaluate(resnet18, val_loader)\n\n    print(f\"\\n📊 Epoch {epoch+1}/{epochs}\")\n    print(f\"Train Loss: {np.mean(train_losses):.4f}\")\n    print(f\"Train Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f} | Precision: {train_metrics['precision']:.4f} | Recall: {train_metrics['recall']:.4f} | AUC: {train_metrics['auc']:.4f}\")\n    print(f\"Val   Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f} | Precision: {val_metrics['precision']:.4f} | Recall: {val_metrics['recall']:.4f} | AUC: {val_metrics['auc']:.4f}\")\n\n    # Save best model\n    if val_metrics['accuracy'] > best_val_acc:\n        best_val_acc = val_metrics['accuracy']\n        torch.save(resnet18.state_dict(), 'best_resnet18.pth')\n        print(\"✅ Saved new best model.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:33:41.311784Z","iopub.execute_input":"2025-04-05T05:33:41.312103Z","iopub.status.idle":"2025-04-05T05:46:50.698129Z","shell.execute_reply.started":"2025-04-05T05:33:41.312080Z","shell.execute_reply":"2025-04-05T05:46:50.697291Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 1/10\nTrain Loss: 0.5953\nTrain Acc: 0.8627 | F1: 0.8517 | Precision: 0.8550 | Recall: 0.8627 | AUC: 0.9864\nVal   Acc: 0.8819 | F1: 0.8684 | Precision: 0.8716 | Recall: 0.8819 | AUC: 0.9845\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 2/10\nTrain Loss: 0.3782\nTrain Acc: 0.8911 | F1: 0.8833 | Precision: 0.8858 | Recall: 0.8911 | AUC: 0.9912\nVal   Acc: 0.8884 | F1: 0.8780 | Precision: 0.8789 | Recall: 0.8884 | AUC: 0.9806\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 3/10\nTrain Loss: 0.2930\nTrain Acc: 0.9196 | F1: 0.9182 | Precision: 0.9182 | Recall: 0.9196 | AUC: 0.9944\nVal   Acc: 0.8904 | F1: 0.8892 | Precision: 0.8888 | Recall: 0.8904 | AUC: 0.9601\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 4/10\nTrain Loss: 0.2379\nTrain Acc: 0.9373 | F1: 0.9338 | Precision: 0.9339 | Recall: 0.9373 | AUC: 0.9963\nVal   Acc: 0.9038 | F1: 0.8979 | Precision: 0.8975 | Recall: 0.9038 | AUC: 0.9635\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 16.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 5/10\nTrain Loss: 0.2014\nTrain Acc: 0.9454 | F1: 0.9430 | Precision: 0.9429 | Recall: 0.9454 | AUC: 0.9969\nVal   Acc: 0.8968 | F1: 0.8917 | Precision: 0.8903 | Recall: 0.8968 | AUC: 0.9476\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 16.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 6/10\nTrain Loss: 0.1723\nTrain Acc: 0.9528 | F1: 0.9510 | Precision: 0.9520 | Recall: 0.9528 | AUC: 0.9976\nVal   Acc: 0.9040 | F1: 0.8995 | Precision: 0.9005 | Recall: 0.9040 | AUC: 0.9619\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 7/10\nTrain Loss: 0.1475\nTrain Acc: 0.9643 | F1: 0.9638 | Precision: 0.9638 | Recall: 0.9643 | AUC: 0.9985\nVal   Acc: 0.9087 | F1: 0.9070 | Precision: 0.9066 | Recall: 0.9087 | AUC: 0.9744\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 8/10\nTrain Loss: 0.1286\nTrain Acc: 0.9618 | F1: 0.9609 | Precision: 0.9616 | Recall: 0.9618 | AUC: 0.9985\nVal   Acc: 0.9054 | F1: 0.9014 | Precision: 0.9023 | Recall: 0.9054 | AUC: 0.9655\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 - Training: 100%|██████████| 1043/1043 [01:05<00:00, 15.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 9/10\nTrain Loss: 0.1130\nTrain Acc: 0.9626 | F1: 0.9627 | Precision: 0.9636 | Recall: 0.9626 | AUC: 0.9989\nVal   Acc: 0.9093 | F1: 0.9084 | Precision: 0.9095 | Recall: 0.9093 | AUC: 0.9428\n✅ Saved new best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 - Training: 100%|██████████| 1043/1043 [01:04<00:00, 16.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Epoch 10/10\nTrain Loss: 0.1002\nTrain Acc: 0.9750 | F1: 0.9742 | Precision: 0.9749 | Recall: 0.9750 | AUC: 0.9994\nVal   Acc: 0.9136 | F1: 0.9097 | Precision: 0.9106 | Recall: 0.9136 | AUC: 0.9466\n✅ Saved new best model.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Load the best model\nresnet18.load_state_dict(torch.load('best_resnet18.pth'))\nresnet18.eval()\n\n# Evaluation function with both macro and weighted metrics\ndef evaluate_full(model, loader):\n    model.eval()\n    y_true, y_pred, y_probs = [], [], []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            X = X.repeat(1, 3, 1, 1)\n\n            outputs = model(X)\n            probs = torch.softmax(outputs, dim=1)\n            preds = torch.argmax(probs, dim=1)\n\n            y_true.extend(y.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            y_probs.extend(probs.cpu().numpy())\n\n    results = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n        'precision_macro': precision_score(y_true, y_pred, average='macro'),\n        'precision_weighted': precision_score(y_true, y_pred, average='weighted'),\n        'recall_macro': recall_score(y_true, y_pred, average='macro'),\n        'recall_weighted': recall_score(y_true, y_pred, average='weighted'),\n    }\n\n    try:\n        results['auc_ovr'] = roc_auc_score(y_true, y_probs, multi_class='ovr')\n    except:\n        results['auc_ovr'] = 0.0\n\n    return results\n\n# Evaluate on test set\ntest_metrics = evaluate_full(resnet18, test_loader)\n\n# Display results\nprint(\"\\n📊 Final Test Set Evaluation:\")\nfor metric, value in test_metrics.items():\n    print(f\"{metric}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:50:41.400936Z","iopub.execute_input":"2025-04-05T05:50:41.401290Z","iopub.status.idle":"2025-04-05T05:50:41.692765Z","shell.execute_reply.started":"2025-04-05T05:50:41.401265Z","shell.execute_reply":"2025-04-05T05:50:41.691946Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-30-68da926338f7>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  resnet18.load_state_dict(torch.load('best_resnet18.pth'))\n","output_type":"stream"},{"name":"stdout","text":"\n📊 Final Test Set Evaluation:\naccuracy: 0.7248\nf1_macro: 0.5829\nf1_weighted: 0.7097\nprecision_macro: 0.6167\nprecision_weighted: 0.7520\nrecall_macro: 0.5890\nrecall_weighted: 0.7248\nauc_ovr: 0.9279\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}