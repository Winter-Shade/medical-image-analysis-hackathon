{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11295678,"sourceType":"datasetVersion","datasetId":7063165}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:11:51.476186Z","iopub.execute_input":"2025-04-06T09:11:51.476552Z","iopub.status.idle":"2025-04-06T09:11:51.802985Z","shell.execute_reply.started":"2025-04-06T09:11:51.476522Z","shell.execute_reply":"2025-04-06T09:11:51.802019Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install medmnist kaggle opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:02.293381Z","iopub.execute_input":"2025-04-06T09:12:02.293897Z","iopub.status.idle":"2025-04-06T09:12:05.931269Z","shell.execute_reply.started":"2025-04-06T09:12:02.293859Z","shell.execute_reply":"2025-04-06T09:12:05.930025Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (3.0.2)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\nRequirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.7.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2025.1.31)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2.4.1)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->medmnist) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->medmnist) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torch torchvision medmnist scikit-learn determined torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:05.932712Z","iopub.execute_input":"2025-04-06T09:12:05.932987Z","iopub.status.idle":"2025-04-06T09:12:09.749921Z","shell.execute_reply.started":"2025-04-06T09:12:05.932964Z","shell.execute_reply":"2025-04-06T09:12:09.748993Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (3.0.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: determined in /usr/local/lib/python3.10/dist-packages (0.38.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\nRequirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.7.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from determined) (3.7.5)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from determined) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from determined) (5.9.5)\nRequirement already satisfied: pyzmq>=18.1.0 in /usr/local/lib/python3.10/dist-packages (from determined) (24.0.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from determined) (2025.1.31)\nRequirement already satisfied: requests<2.32.0 in /usr/local/lib/python3.10/dist-packages (from determined) (2.31.0)\nRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from determined) (2.14.0)\nRequirement already satisfied: lomond>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from determined) (0.3.3)\nRequirement already satisfied: pathspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from determined) (0.12.1)\nRequirement already satisfied: azure-core in /usr/local/lib/python3.10/dist-packages (from determined) (1.33.0)\nRequirement already satisfied: azure-storage-blob in /usr/local/lib/python3.10/dist-packages (from determined) (12.25.1)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from determined) (2.5.0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from determined) (1.36.23)\nRequirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from determined) (3.6.2)\nRequirement already satisfied: gitpython>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from determined) (3.1.43)\nRequirement already satisfied: pyOpenSSL>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from determined) (25.0.0)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from determined) (2.9.0.post0)\nRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from determined) (2025.1)\nRequirement already satisfied: tabulate>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from determined) (0.9.0)\nRequirement already satisfied: ruamel.yaml in /usr/local/lib/python3.10/dist-packages (from determined) (0.18.10)\nRequirement already satisfied: docker>=3.7.3 in /usr/local/lib/python3.10/dist-packages (from docker[ssh]>=3.7.3->determined) (7.1.0)\nRequirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from determined) (2.155.0)\nRequirement already satisfied: paramiko>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from determined) (3.5.1)\nRequirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from determined) (1.4.4)\nRequirement already satisfied: analytics-python in /usr/local/lib/python3.10/dist-packages (from determined) (1.4.post1)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker>=3.7.3->docker[ssh]>=3.7.3->determined) (2.3.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.3->determined) (4.0.11)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->determined) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->determined) (2.27.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->determined) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->determined) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->determined) (4.1.1)\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from lomond>=0.3.3->determined) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4.2->determined) (4.3.0)\nRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4.2->determined) (44.0.1)\nRequirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4.2->determined) (1.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<2.32.0->determined) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<2.32.0->determined) (3.10)\nRequirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from analytics-python->determined) (1.6)\nRequirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.10/dist-packages (from analytics-python->determined) (1.10.0)\nRequirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->determined) (0.7.2)\nRequirement already satisfied: botocore<1.37.0,>=1.36.23 in /usr/local/lib/python3.10/dist-packages (from boto3->determined) (1.36.23)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->determined) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from boto3->determined) (0.11.2)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->determined) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->determined) (2.7.2)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->determined) (1.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->determined) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->determined) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->determined) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->determined) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->determined) (3.2.0)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml->determined) (0.2.12)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4.2->determined) (1.17.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.3->determined) (5.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.1->determined) (1.66.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.1->determined) (3.20.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.1->determined) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.1->determined) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.1->determined) (4.9)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.2->determined) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.1->determined) (0.6.1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# %% [code]\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport albumentations as A\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom medmnist import OCTMNIST, BreastMNIST, PneumoniaMNIST, RetinaMNIST, INFO\n\n# Set seed for reproducibility\nseed = 42\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n# %% [markdown]\n# ## 1. Data Loading and Preprocessing\n# \n# Define functions:\n# - `preprocess_general`: For OCTMNIST, PneumoniaMNIST, and BreastMNIST.\n# - `preprocess_retina`: For RetinaMNIST (converts to grayscale, applies median filter and CLAHE).","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:13.698544Z","iopub.execute_input":"2025-04-06T09:12:13.698841Z","iopub.status.idle":"2025-04-06T09:12:17.556518Z","shell.execute_reply.started":"2025-04-06T09:12:13.698818Z","shell.execute_reply":"2025-04-06T09:12:17.555669Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c02d4d213f0>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# %% [code]\ndef preprocess_general(img):\n    if img.ndim == 3 and img.shape[-1] == 3:\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    elif img.ndim == 3 and img.shape[-1] == 1:\n        img = img.squeeze()\n    return img.astype(np.float32) / 255.0\n\ndef preprocess_retina(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    denoised = cv2.medianBlur(gray, 3)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    proc = clahe.apply(denoised)\n    return proc.astype(np.float32) / 255.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:19.748372Z","iopub.execute_input":"2025-04-06T09:12:19.748895Z","iopub.status.idle":"2025-04-06T09:12:19.754142Z","shell.execute_reply.started":"2025-04-06T09:12:19.748868Z","shell.execute_reply":"2025-04-06T09:12:19.753117Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# %% [code]\ndef load_and_preprocess(dataset_cls, offset, is_retina=False):\n    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n    for split in ['train', 'val', 'test']:\n        dataset = dataset_cls(split=split, download=True)\n        for img, label in tqdm(zip(dataset.imgs, dataset.labels.squeeze()), total=len(dataset.imgs), desc=f\"Processing {dataset_cls.__name__} {split}\"):\n            label += offset  # ensure unique label ranges\n            proc_img = preprocess_retina(img) if is_retina else preprocess_general(img)\n            if split == 'train':\n                X_train.append(proc_img)\n                y_train.append(label)\n            elif split == 'val':\n                X_val.append(proc_img)\n                y_val.append(label)\n            else:\n                X_test.append(proc_img)\n                y_test.append(label)\n    return X_train, y_train, X_val, y_val, X_test, y_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:22.453939Z","iopub.execute_input":"2025-04-06T09:12:22.454255Z","iopub.status.idle":"2025-04-06T09:12:22.460136Z","shell.execute_reply.started":"2025-04-06T09:12:22.454228Z","shell.execute_reply":"2025-04-06T09:12:22.459242Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# %% [markdown]\n# **Assign Label Offsets:**  \n# - OCTMNIST: 0–3  \n# - PneumoniaMNIST: next 2 classes  \n# - RetinaMNIST: next 5 classes  \n# - BreastMNIST: last 2 classes  \n# This gives a total of 4+2+5+2 = 13 classes.\n# %% [code]\noffsets = {\n    'octmnist': 0,\n    'pneumoniamnist': len(INFO['octmnist']['label']),              # typically 4\n    'retinamnist': len(INFO['octmnist']['label']) + len(INFO['pneumoniamnist']['label']),  # 4+2=6\n    'breastmnist': len(INFO['octmnist']['label']) + len(INFO['pneumoniamnist']['label']) + len(INFO['retinamnist']['label'])  # 6+5=11\n}\n\n# Load datasets\nX_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\ndatasets = [\n    ('octmnist', OCTMNIST, False),\n    ('pneumoniamnist', PneumoniaMNIST, False),\n    ('retinamnist', RetinaMNIST, True),\n    ('breastmnist', BreastMNIST, False)\n]\nfor name, cls, is_retina in datasets:\n    Xt, yt, Xv, yv, Xte, yte = load_and_preprocess(cls, offsets[name], is_retina)\n    X_train += Xt; y_train += yt\n    X_val   += Xv; y_val   += yv\n    X_test  += Xte; y_test  += yte\n\n# Convert lists to numpy arrays\nX_train = np.array(X_train)\ny_train = np.array(y_train)\nX_val   = np.array(X_val)\ny_val   = np.array(y_val)\nX_test  = np.array(X_test)\ny_test  = np.array(y_test)\n\nprint(\"Train images:\", X_train.shape, \"Train labels:\", y_train.shape)\nprint(\"Validation images:\", X_val.shape, \"Validation labels:\", y_val.shape)\nprint(\"Test images:\", X_test.shape, \"Test labels:\", y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:25.049208Z","iopub.execute_input":"2025-04-06T09:12:25.049566Z","iopub.status.idle":"2025-04-06T09:12:44.105892Z","shell.execute_reply.started":"2025-04-06T09:12:25.049535Z","shell.execute_reply":"2025-04-06T09:12:44.104896Z"}},"outputs":[{"name":"stdout","text":"Downloading https://zenodo.org/records/10519652/files/octmnist.npz?download=1 to /root/.medmnist/octmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 54.9M/54.9M [00:04<00:00, 11.1MB/s]\nProcessing OCTMNIST train: 100%|██████████| 97477/97477 [00:00<00:00, 118390.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/octmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing OCTMNIST val: 100%|██████████| 10832/10832 [00:00<00:00, 118332.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/octmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing OCTMNIST test: 100%|██████████| 1000/1000 [00:00<00:00, 115551.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Downloading https://zenodo.org/records/10519652/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4.17M/4.17M [00:01<00:00, 3.59MB/s]\nProcessing PneumoniaMNIST train: 100%|██████████| 4708/4708 [00:00<00:00, 119084.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing PneumoniaMNIST val: 100%|██████████| 524/524 [00:00<00:00, 129595.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing PneumoniaMNIST test: 100%|██████████| 624/624 [00:00<00:00, 133179.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Downloading https://zenodo.org/records/10519652/files/retinamnist.npz?download=1 to /root/.medmnist/retinamnist.npz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3.29M/3.29M [00:01<00:00, 3.06MB/s]\nProcessing RetinaMNIST train: 100%|██████████| 1080/1080 [00:00<00:00, 7947.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing RetinaMNIST val: 100%|██████████| 120/120 [00:00<00:00, 8904.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing RetinaMNIST test: 100%|██████████| 400/400 [00:00<00:00, 9133.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Downloading https://zenodo.org/records/10519652/files/breastmnist.npz?download=1 to /root/.medmnist/breastmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 560k/560k [00:00<00:00, 798kB/s] \nProcessing BreastMNIST train: 100%|██████████| 546/546 [00:00<00:00, 136055.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing BreastMNIST val: 100%|██████████| 78/78 [00:00<00:00, 61704.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing BreastMNIST test: 100%|██████████| 156/156 [00:00<00:00, 86469.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train images: (103811, 28, 28) Train labels: (103811,)\nValidation images: (11554, 28, 28) Validation labels: (11554,)\nTest images: (2180, 28, 28) Test labels: (2180,)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# %% [markdown]\n# ## 2. Data Augmentation\n# \n# Augment classes in the training set with fewer than 2000 images (expand to 5× the original number).\n# %% [code]\n# Calculate class counts\nunique, counts = np.unique(y_train, return_counts=True)\nclass_counts = dict(zip(unique, counts))\nprint(\"Initial class distribution:\", class_counts)\n\n# Identify classes to augment (less than 2000 images)\naugment_classes = [cls for cls, cnt in class_counts.items() if cnt < 2000]\nprint(\"Classes to augment:\", augment_classes)\n\n# Define augmentation pipeline using Albumentations\n# Define augmentation pipeline using Albumentations (without RandAugment)\naugment_pipeline = A.Compose([\n    A.RandomResizedCrop(28, 28, scale=(0.8, 1.0), p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=15, p=0.5),\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n    A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n    A.OneOf([\n        A.Equalize(p=0.5),\n        A.Solarize(p=0.5),\n        A.Posterize(num_bits=4, p=0.5),\n        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),\n    ], p=0.5)\n])\n\n\naug_imgs, aug_labels = [], []\nfor cls in augment_classes:\n    cls_idxs = np.where(y_train == cls)[0]\n    cls_imgs = X_train[cls_idxs]\n    target_count = 5 * len(cls_imgs)\n    needed = target_count - len(cls_imgs)\n    print(f\"Augmenting class {cls}: need {needed} new samples\")\n    for _ in range(needed):\n        img = cls_imgs[np.random.randint(len(cls_imgs))]\n        # Albumentations expects uint8 images; convert from [0,1] float32\n        aug_img = augment_pipeline(image=(img * 255).astype(np.uint8))['image']\n        aug_img = aug_img.astype(np.float32) / 255.0\n        aug_imgs.append(aug_img)\n        aug_labels.append(cls)\n\nif aug_imgs:\n    X_train = np.concatenate([X_train, np.stack(aug_imgs)])\n    y_train = np.concatenate([y_train, np.array(aug_labels)])\n    print(\"After augmentation, training set shape:\", X_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:44.106912Z","iopub.execute_input":"2025-04-06T09:12:44.107310Z","iopub.status.idle":"2025-04-06T09:12:51.841814Z","shell.execute_reply.started":"2025-04-06T09:12:44.107287Z","shell.execute_reply":"2025-04-06T09:12:51.840947Z"}},"outputs":[{"name":"stdout","text":"Initial class distribution: {0: 33484, 1: 10213, 2: 7754, 3: 46026, 4: 1214, 5: 3494, 6: 486, 7: 128, 8: 206, 9: 194, 10: 66, 11: 147, 12: 399}\nClasses to augment: [4, 6, 7, 8, 9, 10, 11, 12]\nAugmenting class 4: need 4856 new samples\nAugmenting class 6: need 1944 new samples\nAugmenting class 7: need 512 new samples\nAugmenting class 8: need 824 new samples\nAugmenting class 9: need 776 new samples\nAugmenting class 10: need 264 new samples\nAugmenting class 11: need 588 new samples\nAugmenting class 12: need 1596 new samples\nAfter augmentation, training set shape: (115171, 28, 28)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# %% [markdown]\n# ## 3. Create PyTorch Dataset and DataLoader\n# \n# The dataset will reshape images to (1, 28, 28).\n# %% [code]\nclass MedmnistDataset(Dataset):\n    def __init__(self, images, labels):\n        # images shape: (N, 28, 28); add channel dimension\n        self.images = images.reshape(-1, 1, 28, 28).astype(np.float32)\n        self.labels = labels.astype(np.int64)\n    def __len__(self):\n        return len(self.images)\n    def __getitem__(self, idx):\n        return torch.tensor(self.images[idx]), torch.tensor(self.labels[idx])\n    \nbatch_size = 53\ntrain_dataset = MedmnistDataset(X_train, y_train)\nval_dataset   = MedmnistDataset(X_val, y_val)\ntest_dataset  = MedmnistDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:51.843213Z","iopub.execute_input":"2025-04-06T09:12:51.843540Z","iopub.status.idle":"2025-04-06T09:12:51.981579Z","shell.execute_reply.started":"2025-04-06T09:12:51.843516Z","shell.execute_reply":"2025-04-06T09:12:51.980831Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# %% [markdown]\n# ## 4. Define Custom ResNet-50-based Model\n# \n# The model uses:\n# - Base: ResNet-50  \n# - Customizations:\n#   - Adjusted first convolution layer to accept 1-channel input.\n#   - Removed the max pooling layer.\n#   - Final fully connected layer outputs 13 classes.\n# %% [code]\nfrom torchvision import models\n\nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet50, self).__init__()\n        # Load ResNet-50 (without pre-trained weights)\n        self.resnet = models.resnet50(pretrained=False)\n        # Modify conv1 to accept 1-channel input\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        # Remove max pooling layer by replacing with identity\n        self.resnet.maxpool = nn.Identity()\n        # Modify final fully connected layer to output num_classes\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n    def forward(self, x):\n        return self.resnet(x)\n\nnum_classes = 13\nmodel = CustomResNet50(num_classes)\nmodel = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:51.982564Z","iopub.execute_input":"2025-04-06T09:12:51.982813Z","iopub.status.idle":"2025-04-06T09:12:52.616677Z","shell.execute_reply.started":"2025-04-06T09:12:51.982792Z","shell.execute_reply":"2025-04-06T09:12:52.615919Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# %% [markdown]\n# ## 5. Training Setup\n# \n# **Hyperparameters:**\n# - Batch Size: 53  \n# - Learning Rate: 0.01332344940133225  \n# - Weight Decay: 0.00021921795989143406  \n# - Optimizer: SGD with momentum 0.9  \n# - Scheduler: ReduceLROnPlateau\n# %% [code]\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01332344940133225, momentum=0.9, weight_decay=0.00021921795989143406)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:52.617477Z","iopub.execute_input":"2025-04-06T09:12:52.617707Z","iopub.status.idle":"2025-04-06T09:12:52.625606Z","shell.execute_reply.started":"2025-04-06T09:12:52.617685Z","shell.execute_reply":"2025-04-06T09:12:52.624675Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# %% [code]\nimport time\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    for imgs, labels in loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        # The model expects 1-channel input (28x28) so no channel replication is needed.\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * imgs.size(0)\n    return running_loss / len(loader.dataset)\n\ndef evaluate_model(model, loader, device):\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            preds = torch.argmax(outputs, dim=1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n    from sklearn.metrics import accuracy_score\n    return accuracy_score(y_true, y_pred)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_epochs = 10\nbest_val_acc = 0.0\n\nfor epoch in range(num_epochs):\n    start = time.time()\n    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n    val_acc = evaluate_model(model, val_loader, device)\n    scheduler.step(val_acc)\n    end = time.time()\n    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f} | Time: {end-start:.2f}s\")\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_custom_resnet50.pth\")\n        print(\"Saved best model.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:12:57.403373Z","iopub.execute_input":"2025-04-06T09:12:57.403731Z","iopub.status.idle":"2025-04-06T09:37:29.720554Z","shell.execute_reply.started":"2025-04-06T09:12:57.403704Z","shell.execute_reply":"2025-04-06T09:37:29.719577Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 | Loss: 0.8744 | Val Acc: 0.4962 | Time: 148.03s\nSaved best model.\nEpoch 2/10 | Loss: 0.5423 | Val Acc: 0.7989 | Time: 147.11s\nSaved best model.\nEpoch 3/10 | Loss: 0.4301 | Val Acc: 0.8528 | Time: 146.99s\nSaved best model.\nEpoch 4/10 | Loss: 0.4174 | Val Acc: 0.8694 | Time: 147.06s\nSaved best model.\nEpoch 5/10 | Loss: 0.3383 | Val Acc: 0.9023 | Time: 147.02s\nSaved best model.\nEpoch 6/10 | Loss: 0.3102 | Val Acc: 0.8988 | Time: 147.02s\nEpoch 7/10 | Loss: 0.3120 | Val Acc: 0.9088 | Time: 147.02s\nSaved best model.\nEpoch 8/10 | Loss: 0.2754 | Val Acc: 0.9023 | Time: 146.97s\nEpoch 9/10 | Loss: 0.2661 | Val Acc: 0.6613 | Time: 146.92s\nEpoch 10/10 | Loss: 0.3200 | Val Acc: 0.8455 | Time: 146.84s\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# %% [markdown]\n# ## 7. Final Model Saving and Download Instructions\n# \n# The best model is saved as `best_custom_resnet50.pth`.  \n# In Kaggle's Files pane, download this model along with the evaluation script (see next cell).\n# %% [markdown]\n# ## 8. Create Evaluation Script for Local Use\n# \n# This script (saved as `evaluate_model.py`) loads the saved model and evaluates on a provided CSV file.\n# %% [code]\neval_script = r\"\"\"\nimport torch\nimport torch.nn as nn\nfrom torchvision import models\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score\n\nclass MedmnistDataset(Dataset):\n    def __init__(self, csv_path):\n        df = pd.read_csv(csv_path)\n        self.X = df.drop('label', axis=1).values.reshape(-1, 1, 28, 28).astype(np.float32)\n        self.y = df['label'].values.astype(np.int64)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n    \nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet50, self).__init__()\n        self.resnet = models.resnet50(pretrained=False)\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.resnet.maxpool = nn.Identity()\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n    def forward(self, x):\n        return self.resnet(x)\n\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model-path\", type=str, default=\"best_custom_resnet50.pth\", help=\"Path to the trained model\")\n    parser.add_argument(\"--csv-path\", type=str, required=True, help=\"Path to the test CSV file\")\n    parser.add_argument(\"--num-classes\", type=int, default=13, help=\"Number of classes\")\n    args = parser.parse_args()\n    \n    device = torch.device(\"cpu\")\n    model = CustomResNet50(args.num_classes)\n    model.load_state_dict(torch.load(args.model_path, map_location=device))\n    model.eval()\n    \n    dataset = MedmnistDataset(args.csv_path)\n    loader = DataLoader(dataset, batch_size=53, shuffle=False)\n    \n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs = imgs.to(device)\n            outputs = model(imgs)\n            preds = torch.argmax(outputs, dim=1)\n            y_true.extend(labels.numpy())\n            y_pred.extend(preds.numpy())\n    \n    acc = accuracy_score(y_true, y_pred)\n    print(\"Test Accuracy:\", acc)\n\"\"\"\nwith open(\"evaluate_model.py\", \"w\") as f:\n    f.write(eval_script)\nprint(\"Evaluation script saved as evaluate_model.py\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:40:39.030199Z","iopub.execute_input":"2025-04-06T09:40:39.030572Z","iopub.status.idle":"2025-04-06T09:40:39.036548Z","shell.execute_reply.started":"2025-04-06T09:40:39.030540Z","shell.execute_reply":"2025-04-06T09:40:39.035691Z"}},"outputs":[{"name":"stdout","text":"Evaluation script saved as evaluate_model.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Save test dataset as CSV\ndef save_split(X, y, path):\n    # Reshape each image to a 1D vector and create a DataFrame\n    df = pd.DataFrame(X.reshape((X.shape[0], -1)))\n    df['label'] = y\n    df.to_csv(path, index=False)\n    print(f\"Test CSV saved to {path}\")\n\n# Save the test set CSV to \"split_data/test.csv\"\nos.makedirs('split_data', exist_ok=True)\nsave_split(X_test, y_test, \"split_data/test.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:48:12.653179Z","iopub.execute_input":"2025-04-06T09:48:12.653579Z","iopub.status.idle":"2025-04-06T09:48:14.012623Z","shell.execute_reply.started":"2025-04-06T09:48:12.653548Z","shell.execute_reply":"2025-04-06T09:48:14.011734Z"}},"outputs":[{"name":"stdout","text":"Test CSV saved to split_data/test.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n\n# Define the custom ResNet-50 model (same as used during training)\nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet50, self).__init__()\n        self.resnet = models.resnet50(pretrained=False)\n        # Modify the first convolution to accept 1-channel input\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        # Remove max pooling layer\n        self.resnet.maxpool = nn.Identity()\n        # Modify final layer for 13 classes\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n        \n    def forward(self, x):\n        return self.resnet(x)\n\n# Define a dataset class that reads from CSV (each row is a flattened 28x28 image with a 'label' column)\nclass MedmnistDataset(Dataset):\n    def __init__(self, csv_path):\n        df = pd.read_csv(csv_path)\n        # Assume image pixels are stored as flattened values in all columns except 'label'\n        self.X = df.drop('label', axis=1).values.reshape(-1, 1, 28, 28).astype(np.float32)\n        self.y = df['label'].values.astype(np.int64)\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n\n# Load the combined test set CSV\ntest_csv_path = \"/kaggle/working/split_data/test.csv\"  # update if needed\ntest_dataset = MedmnistDataset(test_csv_path)\ntest_loader = DataLoader(test_dataset, batch_size=53, shuffle=False)\n\n# Load the saved model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CustomResNet50(num_classes=13)\nmodel.load_state_dict(torch.load(\"best_custom_resnet50.pth\", map_location=device))\nmodel = model.to(device)\nmodel.eval()\n\n# Evaluate the model on the test set\ny_true, y_pred, y_probs = [], [], []\nwith torch.no_grad():\n    for imgs, labels in test_loader:\n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        probs = torch.softmax(outputs, dim=1)\n        preds = torch.argmax(probs, dim=1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n        y_probs.extend(probs.cpu().numpy())\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='weighted')\nprecision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\ntry:\n    auc = roc_auc_score(y_true, y_probs, multi_class='ovr', average='weighted')\nexcept Exception as e:\n    auc = None\n    print(\"AUC computation error:\", e)\n\n# Print the evaluation metrics\nprint(\"Test Accuracy: {:.4f}\".format(accuracy))\nprint(\"Test F1 Score: {:.4f}\".format(f1))\nprint(\"Test Precision: {:.4f}\".format(precision))\nprint(\"Test Recall: {:.4f}\".format(recall))\nprint(\"Test AUC: {:.4f}\".format(auc) if auc is not None else \"Test AUC: Error computing AUC\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:56:00.617149Z","iopub.execute_input":"2025-04-06T09:56:00.617475Z","iopub.status.idle":"2025-04-06T09:56:02.009057Z","shell.execute_reply.started":"2025-04-06T09:56:00.617449Z","shell.execute_reply":"2025-04-06T09:56:02.008237Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n<ipython-input-24-2f8cc0f96ad0>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"best_custom_resnet50.pth\", map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.7450\nTest F1 Score: 0.7060\nTest Precision: 0.7438\nTest Recall: 0.7450\nTest AUC: 0.9821\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Assuming y_true and y_pred are your true labels and predicted labels respectively\nreport = classification_report(y_true, y_pred, target_names=[f'Class {i}' for i in range(13)])\n\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:53:39.366583Z","iopub.execute_input":"2025-04-06T09:53:39.366918Z","iopub.status.idle":"2025-04-06T09:53:39.383560Z","shell.execute_reply.started":"2025-04-06T09:53:39.366895Z","shell.execute_reply":"2025-04-06T09:53:39.382657Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class 0       0.62      0.95      0.75       250\n     Class 1       0.89      0.83      0.86       250\n     Class 2       0.98      0.34      0.50       250\n     Class 3       0.79      0.96      0.87       250\n     Class 4       0.98      0.69      0.81       234\n     Class 5       0.84      0.99      0.91       390\n     Class 6       0.45      0.99      0.62       174\n     Class 7       0.00      0.00      0.00        46\n     Class 8       0.00      0.00      0.00        92\n     Class 9       0.58      0.16      0.25        68\n    Class 10       0.00      0.00      0.00        20\n    Class 11       0.73      0.52      0.61        42\n    Class 12       0.84      0.91      0.87       114\n\n    accuracy                           0.74      2180\n   macro avg       0.59      0.56      0.54      2180\nweighted avg       0.74      0.74      0.71      2180\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}