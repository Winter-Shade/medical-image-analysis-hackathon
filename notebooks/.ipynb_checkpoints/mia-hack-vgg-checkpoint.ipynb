{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922589a5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T19:49:25.897079Z",
     "iopub.status.busy": "2025-04-06T19:49:25.896878Z",
     "iopub.status.idle": "2025-04-06T19:49:32.625800Z",
     "shell.execute_reply": "2025-04-06T19:49:32.624787Z",
     "shell.execute_reply.started": "2025-04-06T19:49:25.897061Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-04-06T21:46:48.393400",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install medmnist\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb116c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T19:49:32.627482Z",
     "iopub.status.busy": "2025-04-06T19:49:32.627121Z",
     "iopub.status.idle": "2025-04-06T19:49:39.292676Z",
     "shell.execute_reply": "2025-04-06T19:49:39.291877Z",
     "shell.execute_reply.started": "2025-04-06T19:49:32.627445Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import random_split\n",
    "from medmnist import OCTMNIST, PneumoniaMNIST, RetinaMNIST,BreastMNIST\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean for RGB\n",
    "                         [0.229, 0.224, 0.225])  # ImageNet std for RGB\n",
    "])\n",
    "\n",
    "# Custom Dataset class to handle merged datasets and apply offsets\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datasets, offsets, transform=None):\n",
    "        self.datasets = datasets\n",
    "        self.offsets = offsets\n",
    "        self.transform = transform\n",
    "        self.merged_samples = self._merge_datasets()\n",
    "\n",
    "    def _merge_datasets(self):\n",
    "        samples = []\n",
    "        for name, dataset in self.datasets.items():\n",
    "            offset = self.offsets[name]\n",
    "            samples.extend(self.offset_dataset(dataset, offset))\n",
    "        return samples\n",
    "\n",
    "    def offset_dataset(self, dataset, offset):\n",
    "        new_samples = []\n",
    "        for x, y in dataset:\n",
    "            new_y = torch.tensor([y[0] + offset])\n",
    "            new_samples.append((x, new_y))\n",
    "        return new_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.merged_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.merged_samples[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "# Load the datasets\n",
    "datasets = {\n",
    "    'oct': OCTMNIST(split='train', transform=None, download=True),\n",
    "    'pneu': PneumoniaMNIST(split='train', transform=None, download=True),\n",
    "    'retina': RetinaMNIST(split='train', transform=None, download=True),\n",
    "    'breast': BreastMNIST(split='train', transform=None, download=True)\n",
    "}\n",
    "\n",
    "# Set offsets to distinguish different classes in each dataset\n",
    "offsets = {'oct': 0, 'pneu': 4, 'retina': 6, 'breast': 11}\n",
    "\n",
    "# Create the custom dataset and apply transformations\n",
    "custom_dataset = CustomDataset(datasets, offsets, transform=transform)\n",
    "\n",
    "len1=len(custom_dataset)//2\n",
    "len2=len(custom_dataset) - len1\n",
    "\n",
    "first_half, second_half = random_split(custom_dataset, [len1, len2])\n",
    "loader1 = DataLoader(first_half, batch_size=32, shuffle=True)\n",
    "loader2 = DataLoader(second_half, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Train_loader1 size:{len(loader1)}\")\n",
    "print(f\"Train_loader2 size:{len(loader2)}\")\n",
    "#Creating the val datasets \n",
    "test_datasets = {\n",
    "    'oct': OCTMNIST(split='test', transform=None, download=True),\n",
    "    'pneu': PneumoniaMNIST(split='test', transform=None, download=True),\n",
    "    'retina': RetinaMNIST(split='test', transform=None, download=True),\n",
    "    'breast': BreastMNIST(split='test', transform=None, download=True)\n",
    "}\n",
    "\n",
    "offsets = {'oct': 0, 'pneu': 4, 'retina': 6, 'breast': 11}\n",
    "\n",
    "# Create evaluation dataset and loader\n",
    "eval_dataset = CustomDataset(test_datasets, offsets, transform=transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "print(f\"Eval_loader size:{len(eval_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d0768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T19:49:39.293830Z",
     "iopub.status.busy": "2025-04-06T19:49:39.293447Z",
     "iopub.status.idle": "2025-04-06T19:49:39.297245Z",
     "shell.execute_reply": "2025-04-06T19:49:39.296340Z",
     "shell.execute_reply.started": "2025-04-06T19:49:39.293807Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, (inputs, labels) in enumerate(loader1):\n",
    "#     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#     print(f\"Batch {i} - Inputs: {inputs.shape}, Labels: {labels.shape}\")\n",
    "#     labels = labels.squeeze()\n",
    "#     outputs = model(inputs)\n",
    "#     print(f\"Batch {i} - Outputs: {outputs.shape}, Labels: {labels.shape}\")\n",
    "#     if inputs.size(0) != labels.size(0):\n",
    "#         print(f\"Batch {i} - Mismatch detected!\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caded21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T19:49:39.298310Z",
     "iopub.status.busy": "2025-04-06T19:49:39.297999Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "# Enable synchronous CUDA errors\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "new_features = nn.Sequential()\n",
    "pool_indices_to_remove = {23, 30}  # Remove the last 2 pooling layers (indices from vgg16.features)\n",
    "\n",
    "for i, layer in enumerate(model.features):\n",
    "    if i not in pool_indices_to_remove or not isinstance(layer, nn.MaxPool2d):\n",
    "        new_features.add_module(str(len(new_features)), layer)\n",
    "\n",
    "\n",
    "model.features = new_features\n",
    "\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "# Step 4: Modify the classifier (as in your original code)\n",
    "model.classifier[6] = nn.Linear(4096, 13)  # Output 13 classes\n",
    "\n",
    "# Optional: Print the modified model to verify\n",
    "print(model)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "# weights_path = '/kaggle/working/vgg16_model.pth'  # Adjust path if needed in Kaggle\n",
    "# state_dict = torch.load(weights_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# 3. Move model to appropriate device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(loader1):  # Replace 'loader' with your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.squeeze(dim=1)\n",
    "\n",
    "        # Validate labels\n",
    "        if labels.max() >= 13 or labels.min() < 0:\n",
    "            print(f\"Batch {i} labels: {labels}\")\n",
    "            raise ValueError(\"Labels must be in range [0, 12]\")\n",
    "\n",
    "        # Ensure correct dtype\n",
    "        labels = labels.long()  # Force to torch.long if not already\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Check for NaN/Inf (optional debugging)\n",
    "        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "            print(f\"Batch {i} outputs contain NaN/Inf: {outputs}\")\n",
    "            raise ValueError(\"Invalid outputs\")\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader1):.4f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save(model.state_dict(), 'vgg16_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c17a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(loader2):  # Replace 'loader' with your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.squeeze(dim=1)\n",
    "\n",
    "        # Validate labels\n",
    "        if labels.max() >= 13 or labels.min() < 0:\n",
    "            print(f\"Batch {i} labels: {labels}\")\n",
    "            raise ValueError(\"Labels must be in range [0, 12]\")\n",
    "\n",
    "        # Ensure correct dtype\n",
    "        labels = labels.long()  # Force to torch.long if not already\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Check for NaN/Inf (optional debugging)\n",
    "        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "            print(f\"Batch {i} outputs contain NaN/Inf: {outputs}\")\n",
    "            raise ValueError(\"Invalid outputs\")\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader2):.4f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save(model.state_dict(), 'vgg16_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685523c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, device, num_classes=13):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).squeeze()  # Squeeze targets\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Probabilities for AUC\n",
    "            _, predicted = torch.max(outputs, dim=1)  # Predicted classes\n",
    "\n",
    "            # Collect predictions, labels, and probabilities\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # F1 Score (macro average for multi-class)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # Precision and Recall (macro average)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # AUC (one-vs-rest for multi-class)\n",
    "    # Convert labels to one-hot encoding for AUC calculation\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "    except ValueError as e:\n",
    "        print(f\"AUC calculation failed: {e}\")\n",
    "        auc = None\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score (Macro): {f1:.4f}\")\n",
    "    print(f\"Precision (Macro): {precision:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall:.4f}\")\n",
    "    print(f\"AUC (One-vs-Rest, Macro): {auc:.4f}\" if auc is not None else \"AUC: N/A\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    # Return all metrics as a dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model, eval_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64147e2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Evaluation phase\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).squeeze()\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(model,eval_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01919dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6969c74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.name \"Nab-magna\"\n",
    "!git config --global user.email \"mohdnabeel19sc@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b32817",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "github_token = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "\n",
    "# Clone repo\n",
    "repo_url = f\"https://yourusername:{github_token}@github.com/yourusername/my-model-weights.git\"\n",
    "!git clone {repo_url}\n",
    "\n",
    "# Move weights\n",
    "!mv /kaggle/working/model_weights.h5 /kaggle/working/my-model-weights/\n",
    "\n",
    "# Commit and push\n",
    "%cd /kaggle/working/my-model-weights\n",
    "!git add .\n",
    "!git commit -m \"Add model weights from Kaggle\"\n",
    "!git push origin main"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-06T21:46:45.822123",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}