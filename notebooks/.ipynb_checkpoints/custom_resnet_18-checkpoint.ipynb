{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab573204-8851-4c96-8838-551eea4d59ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medmnist in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.0.2)\n",
      "Requirement already satisfied: albumentations in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.0.5)\n",
      "Requirement already satisfied: opencv-python in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (11.1.0)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (1.26.4)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (2.1.4)\n",
      "Requirement already satisfied: scikit-image in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (0.25.2)\n",
      "Requirement already satisfied: fire in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albumentations) (1.11.4)\n",
      "Requirement already satisfied: PyYAML in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albumentations) (2.10.6)\n",
      "Requirement already satisfied: albucore==0.0.23 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albumentations) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albucore==0.0.23->albumentations) (3.12.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: termcolor in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fire->medmnist) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->medmnist) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->medmnist) (2025.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist albumentations opencv-python matplotlib pillow torch torchvision scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbfb2ce-a8c5-4154-9ea7-0184bed3cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/octmnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/octmnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/octmnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /teamspace/studios/this_studio/.medmnist/retinamnist.npz\n",
      "\n",
      "ðŸ“Š Train Set Class Distribution:\n",
      "Class 0: 33484\n",
      "Class 1: 10213\n",
      "Class 2: 7754\n",
      "Class 3: 46026\n",
      "Class 4: 147\n",
      "Class 5: 399\n",
      "Class 6: 1214\n",
      "Class 7: 3494\n",
      "Class 8: 486\n",
      "Class 9: 128\n",
      "Class 10: 206\n",
      "Class 11: 194\n",
      "Class 12: 66\n",
      "\n",
      "ðŸ“Š Validation Set Class Distribution:\n",
      "Class 0: 3721\n",
      "Class 1: 1135\n",
      "Class 2: 862\n",
      "Class 3: 5114\n",
      "Class 4: 21\n",
      "Class 5: 57\n",
      "Class 6: 135\n",
      "Class 7: 389\n",
      "Class 8: 54\n",
      "Class 9: 12\n",
      "Class 10: 28\n",
      "Class 11: 20\n",
      "Class 12: 6\n",
      "\n",
      "ðŸ“Š Test Set Class Distribution:\n",
      "Class 0: 250\n",
      "Class 1: 250\n",
      "Class 2: 250\n",
      "Class 3: 250\n",
      "Class 4: 42\n",
      "Class 5: 114\n",
      "Class 6: 234\n",
      "Class 7: 390\n",
      "Class 8: 174\n",
      "Class 9: 46\n",
      "Class 10: 92\n",
      "Class 11: 68\n",
      "Class 12: 20\n",
      "\n",
      "âœ… Augmented with 29666 new samples\n",
      "\n",
      "âœ… Saved train, val, and test CSVs to 'split_data/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from medmnist import OCTMNIST, BreastMNIST, PneumoniaMNIST, RetinaMNIST, INFO\n",
    "\n",
    "# Output directory\n",
    "os.makedirs('split_data', exist_ok=True)\n",
    "\n",
    "# Offsets for label uniqueness\n",
    "offsets = {\n",
    "    'octmnist': 0,\n",
    "    'breastmnist': len(INFO['octmnist']['label']),\n",
    "    'pneumoniamnist': len(INFO['octmnist']['label']) + len(INFO['breastmnist']['label']),\n",
    "    'retinamnist': len(INFO['octmnist']['label']) + len(INFO['breastmnist']['label']) + len(INFO['pneumoniamnist']['label']),\n",
    "}\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_general(img):\n",
    "    if img.ndim == 3 and img.shape[-1] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif img.ndim == 3 and img.shape[-1] == 1:\n",
    "        img = img.squeeze()\n",
    "    return img.astype(np.float32) / 255.0\n",
    "\n",
    "def preprocess_retina(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = cv2.medianBlur(gray, 3)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(denoised).astype(np.float32) / 255.0\n",
    "\n",
    "# Load + preprocess\n",
    "def load_and_preprocess(dataset_cls, offset, is_retina=False):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "    for split_name in ['train', 'val', 'test']:\n",
    "        dataset = dataset_cls(split=split_name, download=True)\n",
    "        for img, label in zip(dataset.imgs, dataset.labels.squeeze()):\n",
    "            label += offset\n",
    "            \n",
    "            if split_name == 'train':\n",
    "                proc_img = preprocess_retina(img) if is_retina else preprocess_general(img)\n",
    "                X_train.append(proc_img)\n",
    "                y_train.append(label)\n",
    "            elif split_name == 'val':\n",
    "                proc_img = preprocess_general(img)\n",
    "                X_val.append(proc_img)\n",
    "                y_val.append(label)\n",
    "            else:\n",
    "                proc_img = preprocess_general(img)\n",
    "                X_test.append(proc_img)\n",
    "                y_test.append(label)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Master load\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "for name, cls in zip(['octmnist', 'breastmnist', 'pneumoniamnist', 'retinamnist'],\n",
    "                     [OCTMNIST, BreastMNIST, PneumoniaMNIST, RetinaMNIST]):\n",
    "    is_retina = (name == 'retinamnist')\n",
    "    Xt, yt, Xv, yv, Xte, yte = load_and_preprocess(cls, offsets[name], is_retina)\n",
    "    X_train += Xt\n",
    "    y_train += yt\n",
    "    X_val += Xv\n",
    "    y_val += yv\n",
    "    X_test += Xte\n",
    "    y_test += yte\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Print distributions\n",
    "def print_distribution(name, labels):\n",
    "    print(f\"\\nðŸ“Š {name} Set Class Distribution:\")\n",
    "    for cls, count in zip(*np.unique(labels, return_counts=True)):\n",
    "        print(f\"Class {cls}: {count}\")\n",
    "\n",
    "print_distribution(\"Train\", y_train)\n",
    "print_distribution(\"Validation\", y_val)\n",
    "print_distribution(\"Test\", y_test)\n",
    "\n",
    "# Augmentation\n",
    "AUGMENT_CLASSES = [cls for cls, count in zip(*np.unique(y_train, return_counts=True)) if count < 4000]\n",
    "augment = A.Compose([\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.ElasticTransform(p=0.2),\n",
    "])\n",
    "\n",
    "aug_imgs, aug_labels = [], []\n",
    "for cls in AUGMENT_CLASSES:\n",
    "    cls_idxs = np.where(y_train == cls)[0]\n",
    "    cls_imgs = X_train[cls_idxs]\n",
    "    needed = 4000 - len(cls_imgs)\n",
    "    for _ in range(needed):\n",
    "        img = cls_imgs[np.random.randint(len(cls_imgs))]\n",
    "        img_aug = augment(image=(img * 255).astype(np.uint8))['image']\n",
    "        aug_imgs.append(img_aug.astype(np.float32) / 255.0)\n",
    "        aug_labels.append(cls)\n",
    "\n",
    "# Append\n",
    "if aug_imgs:\n",
    "    X_train = np.concatenate([X_train, np.stack(aug_imgs)])\n",
    "    y_train = np.concatenate([y_train, np.array(aug_labels)])\n",
    "    print(f\"\\nâœ… Augmented with {len(aug_labels)} new samples\")\n",
    "\n",
    "# Save\n",
    "def save_split(X, y, path):\n",
    "    df = pd.DataFrame(X.reshape((X.shape[0], -1)))\n",
    "    df['label'] = y\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "save_split(X_train, y_train, \"split_data/train.csv\")\n",
    "save_split(X_val, y_val, \"split_data/val.csv\")\n",
    "save_split(X_test, y_test, \"split_data/test.csv\")\n",
    "\n",
    "print(\"\\nâœ… Saved train, val, and test CSVs to 'split_data/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df54cf43-5f5d-4268-bcc5-e357641f299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Train Set Class Distribution:\n",
      "Class 0: 33484\n",
      "Class 1: 10213\n",
      "Class 2: 7754\n",
      "Class 3: 46026\n",
      "Class 4: 4000\n",
      "Class 5: 4000\n",
      "Class 6: 4000\n",
      "Class 7: 4000\n",
      "Class 8: 4000\n",
      "Class 9: 4000\n",
      "Class 10: 4000\n",
      "Class 11: 4000\n",
      "Class 12: 4000\n",
      "\n",
      "ðŸ“Š Validation Set Class Distribution:\n",
      "Class 0: 3721\n",
      "Class 1: 1135\n",
      "Class 2: 862\n",
      "Class 3: 5114\n",
      "Class 4: 21\n",
      "Class 5: 57\n",
      "Class 6: 135\n",
      "Class 7: 389\n",
      "Class 8: 54\n",
      "Class 9: 12\n",
      "Class 10: 28\n",
      "Class 11: 20\n",
      "Class 12: 6\n",
      "\n",
      "ðŸ“Š Test Set Class Distribution:\n",
      "Class 0: 250\n",
      "Class 1: 250\n",
      "Class 2: 250\n",
      "Class 3: 250\n",
      "Class 4: 42\n",
      "Class 5: 114\n",
      "Class 6: 234\n",
      "Class 7: 390\n",
      "Class 8: 174\n",
      "Class 9: 46\n",
      "Class 10: 92\n",
      "Class 11: 68\n",
      "Class 12: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load processed splits\n",
    "df_train = pd.read_csv(\"split_data/train.csv\")\n",
    "df_val = pd.read_csv(\"split_data/val.csv\")\n",
    "df_test = pd.read_csv(\"split_data/test.csv\")\n",
    "\n",
    "def print_class_distribution(df, name):\n",
    "    labels = df['label'].values\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\nðŸ“Š {name} Set Class Distribution:\")\n",
    "    for u, c in zip(unique, counts):\n",
    "        print(f\"Class {u}: {c}\")\n",
    "\n",
    "print_class_distribution(df_train, \"Train\")\n",
    "print_class_distribution(df_val, \"Validation\")\n",
    "print_class_distribution(df_test, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a940e82-04d3-44e6-913f-d8439790d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7104ff39-a417-4f50-8895-722b0825112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=13):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        resnet18 = models.resnet18(weights=None)  # Load base architecture\n",
    "\n",
    "        resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        resnet18.maxpool = nn.Identity()\n",
    "\n",
    "        resnet18.layer1[0].conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        resnet18.layer1[0].conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        resnet18.layer2[0].conv1 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        resnet18.layer2[0].conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        resnet18.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.model = resnet18\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d27be3d-9887-4f30-847e-2ff869f5f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class MedDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.X = df.drop(columns=['label']).values.reshape(-1, 1, 28, 28).astype(np.float32)\n",
    "        self.y = df['label'].values.astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(MedDataset('split_data/train.csv'), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(MedDataset('split_data/val.csv'), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(MedDataset('split_data/test.csv'), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59230cff-ef7b-4bdd-944a-13115960ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 38.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 1/10\n",
      "Train Loss: 0.6139\n",
      "Train Acc: 0.8445 | F1: 0.8303 | Precision: 0.8527 | Recall: 0.7352 | AUC: 0.9868\n",
      "Val   Acc: 0.8753 | F1: 0.8676 | Precision: 0.8716 | Recall: 0.5928 | AUC: 0.9854\n",
      "âœ… Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 2/10\n",
      "Train Loss: 0.3402\n",
      "Train Acc: 0.8988 | F1: 0.8891 | Precision: 0.9038 | Recall: 0.8389 | AUC: 0.9941\n",
      "Val   Acc: 0.8967 | F1: 0.8849 | Precision: 0.8905 | Recall: 0.6466 | AUC: 0.9890\n",
      "âœ… Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 3/10\n",
      "Train Loss: 0.2302\n",
      "Train Acc: 0.9227 | F1: 0.9168 | Precision: 0.9269 | Recall: 0.8941 | AUC: 0.9957\n",
      "Val   Acc: 0.8934 | F1: 0.8818 | Precision: 0.8901 | Recall: 0.6146 | AUC: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 4/10\n",
      "Train Loss: 0.1680\n",
      "Train Acc: 0.9291 | F1: 0.9231 | Precision: 0.9360 | Recall: 0.8904 | AUC: 0.9976\n",
      "Val   Acc: 0.8993 | F1: 0.8873 | Precision: 0.8971 | Recall: 0.6131 | AUC: 0.9895\n",
      "âœ… Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 5/10\n",
      "Train Loss: 0.1302\n",
      "Train Acc: 0.9536 | F1: 0.9540 | Precision: 0.9558 | Recall: 0.9495 | AUC: 0.9984\n",
      "Val   Acc: 0.8985 | F1: 0.8990 | Precision: 0.9024 | Recall: 0.6723 | AUC: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 6/10\n",
      "Train Loss: 0.1032\n",
      "Train Acc: 0.9709 | F1: 0.9707 | Precision: 0.9718 | Recall: 0.9559 | AUC: 0.9994\n",
      "Val   Acc: 0.9107 | F1: 0.9094 | Precision: 0.9114 | Recall: 0.6280 | AUC: 0.9848\n",
      "âœ… Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 7/10\n",
      "Train Loss: 0.0833\n",
      "Train Acc: 0.9742 | F1: 0.9744 | Precision: 0.9756 | Recall: 0.9638 | AUC: 0.9995\n",
      "Val   Acc: 0.9154 | F1: 0.9143 | Precision: 0.9136 | Recall: 0.6474 | AUC: 0.9876\n",
      "âœ… Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 8/10\n",
      "Train Loss: 0.0686\n",
      "Train Acc: 0.9692 | F1: 0.9690 | Precision: 0.9700 | Recall: 0.9669 | AUC: 0.9994\n",
      "Val   Acc: 0.8942 | F1: 0.8913 | Precision: 0.8937 | Recall: 0.6342 | AUC: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 9/10\n",
      "Train Loss: 0.0543\n",
      "Train Acc: 0.9771 | F1: 0.9771 | Precision: 0.9797 | Recall: 0.9619 | AUC: 0.9998\n",
      "Val   Acc: 0.9147 | F1: 0.9136 | Precision: 0.9137 | Recall: 0.6382 | AUC: 0.9797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:13<00:00, 39.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 10/10\n",
      "Train Loss: 0.0509\n",
      "Train Acc: 0.9745 | F1: 0.9743 | Precision: 0.9749 | Recall: 0.9678 | AUC: 0.9997\n",
      "Val   Acc: 0.9017 | F1: 0.8988 | Precision: 0.9008 | Recall: 0.6441 | AUC: 0.9884\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomResNet18(num_classes=13).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n",
    "    except:\n",
    "        auc = 0.0\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro'),\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    train_metrics = evaluate(model, train_loader)\n",
    "    val_metrics = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"\\nðŸ“Š Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {np.mean(train_losses):.4f}\")\n",
    "    print(f\"Train Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f} | Precision: {train_metrics['precision']:.4f} | Recall: {train_metrics['recall']:.4f} | AUC: {train_metrics['auc']:.4f}\")\n",
    "    print(f\"Val   Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f} | Precision: {val_metrics['precision']:.4f} | Recall: {val_metrics['recall']:.4f} | AUC: {val_metrics['auc']:.4f}\")\n",
    "\n",
    "    if val_metrics['accuracy'] > best_val_acc:\n",
    "        best_val_acc = val_metrics['accuracy']\n",
    "        torch.save(model.state_dict(), 'best_custom_resnet18.pth')\n",
    "        print(\"âœ… Saved new best model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff014d95-980a-48ce-afd4-441d7e99cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Classification metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    weighted_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    macro_recall = recall_score(y_true, y_pred, average='macro')\n",
    "    weighted_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    macro_precision = precision_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n",
    "    except:\n",
    "        auc = 0.0\n",
    "\n",
    "    print(f\"\\nðŸ“Š Evaluation on Test Set:\")\n",
    "    print(f\"Accuracy:           {accuracy:.4f}\")\n",
    "    print(f\"Weighted Recall:    {weighted_recall:.4f}\")\n",
    "    print(f\"Macro Recall:       {macro_recall:.4f}\")\n",
    "    print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
    "    print(f\"Macro Precision:    {macro_precision:.4f}\")\n",
    "    print(f\"AUC Score:          {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad314d50-ea84-4db5-90d9-5f0021d88ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation on Test Set:\n",
      "Accuracy:           0.7229\n",
      "Weighted Recall:    0.7229\n",
      "Macro Recall:       0.5723\n",
      "Weighted Precision: 0.7379\n",
      "Macro Precision:    0.6112\n",
      "AUC Score:          0.9481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomResNet18(num_classes=13).to(device)\n",
    "model.load_state_dict(torch.load(\"best_custom_resnet18.pth\"))\n",
    "model.eval()\n",
    "\n",
    "evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58409c6c-7aa1-4703-a3af-dd1b55eb5847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
