{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2cf550",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T20:05:42.290978Z",
     "iopub.status.busy": "2025-04-06T20:05:42.290572Z",
     "iopub.status.idle": "2025-04-06T20:05:52.509976Z",
     "shell.execute_reply": "2025-04-06T20:05:52.508812Z"
    },
    "papermill": {
     "duration": 10.226039,
     "end_time": "2025-04-06T20:05:52.512370",
     "exception": false,
     "start_time": "2025-04-06T20:05:42.286331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fire (from medmnist)\r\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2.4.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\r\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\r\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->medmnist) (1.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->medmnist) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->medmnist) (2024.2.0)\r\n",
      "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: fire\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=e1a8c7b01644283b9f3e519a59849a7ac4bc4e1660fc49535d443ed0e5849041\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\r\n",
      "Successfully built fire\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: fire, medmnist\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed fire-0.7.0 medmnist-3.0.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d37742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T07:16:16.156084Z",
     "iopub.status.busy": "2025-04-06T07:16:16.155827Z",
     "iopub.status.idle": "2025-04-06T07:16:41.337985Z",
     "shell.execute_reply": "2025-04-06T07:16:41.337036Z",
     "shell.execute_reply.started": "2025-04-06T07:16:16.156063Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-04-06T20:05:52.516463",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import random_split\n",
    "from medmnist import OCTMNIST, PneumoniaMNIST, RetinaMNIST,BreastMNIST\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean for RGB\n",
    "                         [0.229, 0.224, 0.225])  # ImageNet std for RGB\n",
    "])\n",
    "\n",
    "# Custom Dataset class to handle merged datasets and apply offsets\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datasets, offsets, transform=None):\n",
    "        self.datasets = datasets\n",
    "        self.offsets = offsets\n",
    "        self.transform = transform\n",
    "        self.merged_samples = self._merge_datasets()\n",
    "\n",
    "    def _merge_datasets(self):\n",
    "        samples = []\n",
    "        for name, dataset in self.datasets.items():\n",
    "            offset = self.offsets[name]\n",
    "            samples.extend(self.offset_dataset(dataset, offset))\n",
    "        return samples\n",
    "\n",
    "    def offset_dataset(self, dataset, offset):\n",
    "        new_samples = []\n",
    "        for x, y in dataset:\n",
    "            new_y = torch.tensor([y[0] + offset])\n",
    "            new_samples.append((x, new_y))\n",
    "        return new_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.merged_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.merged_samples[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "# Load the datasets\n",
    "datasets = {\n",
    "    'oct': OCTMNIST(split='train', transform=None, download=True),\n",
    "    'pneu': PneumoniaMNIST(split='train', transform=None, download=True),\n",
    "    'retina': RetinaMNIST(split='train', transform=None, download=True),\n",
    "    'breast': BreastMNIST(split='train', transform=None, download=True)\n",
    "}\n",
    "\n",
    "# Set offsets to distinguish different classes in each dataset\n",
    "offsets = {'oct': 0, 'pneu': 4, 'retina': 6, 'breast': 11}\n",
    "\n",
    "# Create the custom dataset and apply transformations\n",
    "custom_dataset = CustomDataset(datasets, offsets, transform=transform)\n",
    "\n",
    "len1=len(custom_dataset)//2\n",
    "len2=len(custom_dataset) - len1\n",
    "\n",
    "first_half, second_half = random_split(custom_dataset, [len1, len2])\n",
    "loader1 = DataLoader(first_half, batch_size=32, shuffle=True)\n",
    "loader2 = DataLoader(second_half, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Train_loader1 size:{len(loader1)}\")\n",
    "print(f\"Train_loader2 size:{len(loader2)}\")\n",
    "#Creating the val datasets \n",
    "test_datasets = {\n",
    "    'oct': OCTMNIST(split='test', transform=None, download=True),\n",
    "    'pneu': PneumoniaMNIST(split='test', transform=None, download=True),\n",
    "    'retina': RetinaMNIST(split='test', transform=None, download=True),\n",
    "    'breast': BreastMNIST(split='test', transform=None, download=True)\n",
    "}\n",
    "\n",
    "offsets = {'oct': 0, 'pneu': 4, 'retina': 6, 'breast': 11}\n",
    "\n",
    "# Create evaluation dataset and loader\n",
    "eval_dataset = CustomDataset(test_datasets, offsets, transform=transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "print(f\"Eval_loader size:{len(eval_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b44fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T07:16:41.340216Z",
     "iopub.status.busy": "2025-04-06T07:16:41.339806Z",
     "iopub.status.idle": "2025-04-06T08:07:00.035267Z",
     "shell.execute_reply": "2025-04-06T08:07:00.034355Z",
     "shell.execute_reply.started": "2025-04-06T07:16:41.340187Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "# Enable synchronous CUDA errors\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "aux_factor=0.3\n",
    "# Load pretrained VGG16 model\n",
    "model = models.inception_v3(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(2048, 13)\n",
    "model.AuxLogits.fc = torch.nn.Linear(768, 13)\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.AuxLogits.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "# 3. Move model to appropriate device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(loader1):\n",
    "        if inputs.size(0) == 1:  # Skip batches with size 1\n",
    "            continue\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.squeeze(dim=1)\n",
    "\n",
    "        # Validate labels\n",
    "        if labels.max() >= 13 or labels.min() < 0:\n",
    "            print(f\"Batch {i} labels: {labels}\")\n",
    "            raise ValueError(\"Labels must be in range [0, 12]\")\n",
    "\n",
    "        # Ensure correct dtype\n",
    "        labels = labels.long()  # Force to torch.long if not already\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #outputs has two auxlogits and logits \n",
    "        aux_logits_loss = criterion(outputs.aux_logits, labels)\n",
    "        logits_loss=criterion(outputs.logits,labels)\n",
    "        total_loss=aux_logits_loss*aux_factor+logits_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += total_loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader1):.4f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# torch.save(model.state_dict(), '_model.pth')\n",
    "# print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5528753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:07:00.037170Z",
     "iopub.status.busy": "2025-04-06T08:07:00.036854Z",
     "iopub.status.idle": "2025-04-06T08:55:29.511078Z",
     "shell.execute_reply": "2025-04-06T08:55:29.510177Z",
     "shell.execute_reply.started": "2025-04-06T08:07:00.037133Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(loader2):  # Replace 'loader' with your DataLoader\n",
    "        if inputs.size(0) == 1:  # Skip batches with size 1\n",
    "            continue\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.squeeze(dim=1)\n",
    "\n",
    "        # Validate labels\n",
    "        if labels.max() >= 13 or labels.min() < 0:\n",
    "            print(f\"Batch {i} labels: {labels}\")\n",
    "            raise ValueError(\"Labels must be in range [0, 12]\")\n",
    "\n",
    "        # Ensure correct dtype\n",
    "        labels = labels.long()  # Force to torch.long if not already\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #outputs has two auxlogits and logits \n",
    "        aux_logits_loss = criterion(outputs.aux_logits, labels)\n",
    "        logits_loss=criterion(outputs.logits,labels)\n",
    "        total_loss=aux_logits_loss*aux_factor+logits_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += total_loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader2):.4f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "torch.save(model.state_dict(), 'inception_v3model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fc5f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:55:29.512090Z",
     "iopub.status.busy": "2025-04-06T08:55:29.511877Z",
     "iopub.status.idle": "2025-04-06T08:55:41.708264Z",
     "shell.execute_reply": "2025-04-06T08:55:41.707254Z",
     "shell.execute_reply.started": "2025-04-06T08:55:29.512073Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, device, num_classes=13):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            if inputs.size(0) == 1: \n",
    "                continue\n",
    "            inputs, targets = inputs.to(device), targets.to(device).squeeze()  # Squeeze targets\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Probabilities for AUC\n",
    "            _, predicted = torch.max(outputs, dim=1)  # Predicted classes\n",
    "\n",
    "            # Collect predictions, labels, and probabilities\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # F1 Score (macro average for multi-class)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # Precision and Recall (macro average)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # AUC (one-vs-rest for multi-class)\n",
    "    # Convert labels to one-hot encoding for AUC calculation\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "    except ValueError as e:\n",
    "        print(f\"AUC calculation failed: {e}\")\n",
    "        auc = None\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score (Macro): {f1:.4f}\")\n",
    "    print(f\"Precision (Macro): {precision:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall:.4f}\")\n",
    "    print(f\"AUC (One-vs-Rest, Macro): {auc:.4f}\" if auc is not None else \"AUC: N/A\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    # Return all metrics as a dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model, eval_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a8d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:55:41.709515Z",
     "iopub.status.busy": "2025-04-06T08:55:41.709261Z",
     "iopub.status.idle": "2025-04-06T08:55:53.505697Z",
     "shell.execute_reply": "2025-04-06T08:55:53.505029Z",
     "shell.execute_reply.started": "2025-04-06T08:55:41.709492Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Evaluation phase\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).squeeze()\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(model,eval_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d4dd8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80831e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:56:40.921645Z",
     "iopub.status.busy": "2025-04-06T08:56:40.921351Z",
     "iopub.status.idle": "2025-04-06T08:56:40.926215Z",
     "shell.execute_reply": "2025-04-06T08:56:40.925266Z",
     "shell.execute_reply.started": "2025-04-06T08:56:40.921625Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('/kaggle/working/inception_v3model.pth', 'w') as zipf:\n",
    "    zipf.write('/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c471d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T09:02:36.658724Z",
     "iopub.status.busy": "2025-04-06T09:02:36.658351Z",
     "iopub.status.idle": "2025-04-06T09:02:37.709983Z",
     "shell.execute_reply": "2025-04-06T09:02:37.709058Z",
     "shell.execute_reply.started": "2025-04-06T09:02:36.658687Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "import shutil\n",
    "# Step 1: Save the model weights\n",
    "torch.save(model.state_dict(), '/kaggle/working/inception_v3model.pth')\n",
    "\n",
    "# Step 2: Zip the saved weights\n",
    "zip_path = '/kaggle/working/inception_v3model.zip'  # Correct zip file name\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    zipf.write('/kaggle/working/inception_v3model.pth', arcname='inception_v3model.pth')\n",
    "\n",
    "shutil.make_archive('inception_v3model.zip', 'zip', '/kaggle/working/inception_v3model.zip')\n",
    "\n",
    "# Step 3: Provide a download link\n",
    "FileLink(zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cafdd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-06T20:05:39.625675",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}